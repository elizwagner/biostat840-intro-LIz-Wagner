[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Liz Wagner",
    "section": "",
    "text": "My name is Liz. I’m studying biostatistics as a Master’s of Science student at the Johns Hopkins Bloomberg School of Public Health. My interests include cancer biology and evaluating how public policy effects those with few resources."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "ScM in Biostatistics | Projected 2024\nJohns Hopkins Bloomberg School of Public Health | Baltimore, MD\nBS in Biology | 2020\nUniversity of Colorado | Denver, CO"
  },
  {
    "objectID": "DataAnalysisProj1.html",
    "href": "DataAnalysisProj1.html",
    "title": "Project 1 Data Analysis",
    "section": "",
    "text": "The datasets for this part of the assignment comes from TidyTuesday.\nData dictionary avaialble here:\n\nhttps://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-09-29\n\nSpecifically, we will explore album sales and lyrics from two artists (Beyoncé and Taylor Swift), The data are available from TidyTuesday from September 2020, which I have provided for you below:\n\nb_lyrics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/beyonce_lyrics.csv')\nts_lyrics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/taylor_swift_lyrics.csv')\nsales <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/sales.csv')\n\nHowever, to avoid re-downloading data, we will check to see if those files already exist using an if() statement:\n\nlibrary(here)\nif(!file.exists(here(\"data\",\"b_lyrics.RDS\"))){\n  b_lyrics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/beyonce_lyrics.csv')\n  ts_lyrics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/taylor_swift_lyrics.csv')\n  sales <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/sales.csv')\n  \n  # save the files to RDS objects\n  saveRDS(b_lyrics, file = here(\"data\",\"b_lyrics.RDS\"))\n  saveRDS(ts_lyrics, file = here(\"data\",\"ts_lyrics.RDS\"))\n  saveRDS(sales, file = here(\"data\",\"sales.RDS\"))\n}\n\n\n\n\n\n\n\nNote\n\n\n\nThe above code will only run if it cannot find the path to the b_lyrics.RDS on your computer. Then, we can just read in these files every time we knit the R Markdown, instead of re-downloading them every time.\n\n\nLet’s load the datasets\n\nb_lyrics <- readRDS(here(\"data\",\"b_lyrics.RDS\"))\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nsales <- readRDS(here(\"data\",\"sales.RDS\"))"
  },
  {
    "objectID": "index.html#scm-in-biostatistics-projected-2024",
    "href": "index.html#scm-in-biostatistics-projected-2024",
    "title": "Liz Wagner",
    "section": "ScM in Biostatistics | Projected 2024",
    "text": "ScM in Biostatistics | Projected 2024\nJohns Hopkins Bloomberg School of Public Health Baltimore, MD"
  },
  {
    "objectID": "index.html#bs-in-biology-2020",
    "href": "index.html#bs-in-biology-2020",
    "title": "Liz Wagner",
    "section": "BS in Biology | 2020",
    "text": "BS in Biology | 2020\nUniversity of Colorado Denver, CO"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-1a",
    "href": "DataAnalysisProj1.html#part-1a",
    "title": "Project 1 Data Analysis",
    "section": "Part 1A",
    "text": "Part 1A\nIn this section, we will do some data wrangling.\n\nUse lubridate to create a column called released that is a Date class. However, to be able to do this, you first need to use stringr to search for pattern that matches things like this “(US)[51]” in a string like this “September 1, 2006 (US)[51]” and removes them. (Note: to get full credit, you must create the regular expression).\nUse forcats to create a factor called country (Note: you may need to collapse some factor levels).\n\n\nsales <- readRDS(here(\"data\",\"sales.RDS\"))\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(stringr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nsales$released <- str_remove_all(string=sales$released, pattern = \"(US)|(UK)|[\\\\[\\\\]\\\\(\\\\)]|(39)|(51)\")\n\nsales <- sales %>% \n  mutate(released=mdy(released)) %>% \n  mutate(country = as.factor(country)) %>%\n  mutate(country = fct_collapse(country,\n  World = c(\"WW\", \"World\"),\n  FR = c(\"FR\", \"FRA\")\n))\n\n\nTransform the sales into a unit that is album sales in millions of dollars.\n\n\nsales$sales <-  as.numeric(sales$sales)/1000000\n\n\nKeep only album sales from the UK, the US or the World.\nAuto print your final wrangled tibble data frame.\n\n\nsalesdf <- sales %>% \n   filter(country == \"UK\"|country == \"US\"| country == \"World\")\nsalesdf\n\n# A tibble: 36 × 8\n   artist       title        country  sales released   re_release  label formats\n   <chr>        <chr>        <fct>    <dbl> <date>     <chr>       <chr> <chr>  \n 1 Taylor Swift Taylor Swift US       5.72  2006-10-24 March 18, … Big … CD, CD…\n 2 Taylor Swift Fearless     World   12     2008-11-11 October 27… Big … CD, CD…\n 3 Taylor Swift Fearless     US       7.18  2008-11-11 October 27… Big … CD, CD…\n 4 Taylor Swift Fearless     UK       0.609 2008-11-11 October 27… Big … CD, CD…\n 5 Taylor Swift Speak Now    World    5     2010-10-25 <NA>        Big … CD, CD…\n 6 Taylor Swift Speak Now    US       4.69  2010-10-25 <NA>        Big … CD, CD…\n 7 Taylor Swift Speak Now    UK       0.169 2010-10-25 <NA>        Big … CD, CD…\n 8 Taylor Swift Red          World    6     2012-10-22 <NA>        Big … CD, CD…\n 9 Taylor Swift Red          US       4.46  2012-10-22 <NA>        Big … CD, CD…\n10 Taylor Swift Red          UK       0.693 2012-10-22 <NA>        Big … CD, CD…\n# … with 26 more rows"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-1b",
    "href": "DataAnalysisProj1.html#part-1b",
    "title": "Project 1 Data Analysis",
    "section": "Part 1B",
    "text": "Part 1B\nIn this section, we will do some more data wrangling followed by summarization using wrangled data from Part 1A.\n\nKeep only album sales from the US.\n\n\nsales1 <- sales %>% \n   filter(country == \"US\")\n\n\nCreate a new column called years_since_release corresponding to the number of years since the release of each album from Beyoncé and Taylor Swift. This should be a whole number and you should round down to “14” if you get a non-whole number like “14.12” years. (Hint: you may find the interval() function from lubridate helpful here, but this is not the only way to do this.)\n\n\nsales1 <- sales %>% \n    mutate(years_since_release=(year(Sys.Date())-year(released)))\n\n\nCalculate the most recent, oldest, and the median years since albums were released for both Beyoncé and Taylor Swift.\n\n\nsales1 %>% \n  filter(artist==\"Taylor Swift\")%>%\n  summarize(median = median(years_since_release),\n            recent = min(years_since_release), \n            oldest = max(years_since_release))\n\n# A tibble: 1 × 3\n  median recent oldest\n   <dbl>  <dbl>  <dbl>\n1      8      2     16\n\nsales1 %>% \n  filter(artist==\"Beyoncé\")%>%\n  summarize(median = median(years_since_release),\n            recent = min(years_since_release), \n            oldest = max(years_since_release))\n\n# A tibble: 1 × 3\n  median recent oldest\n   <dbl>  <dbl>  <dbl>\n1   12.5      6     19"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-1c",
    "href": "DataAnalysisProj1.html#part-1c",
    "title": "Project 1 Data Analysis",
    "section": "Part 1C",
    "text": "Part 1C\nUsing the wrangled data from Part 1A:\n\nCalculate the total album sales for each artist and for each country (only sales from the UK, US, and World).\n\n\nsales2 <- sales %>% \n  filter(country == \"UK\"|country == \"US\"| country == \"World\")%>%\n  group_by(artist, country) %>%\n  summarize(total = sum(sales))\n\n`summarise()` has grouped output by 'artist'. You can override using the\n`.groups` argument.\n\nsales2\n\n# A tibble: 6 × 3\n# Groups:   artist [2]\n  artist       country total\n  <chr>        <fct>   <dbl>\n1 Beyoncé      UK       5.24\n2 Beyoncé      US      17.7 \n3 Beyoncé      World   34.5 \n4 Taylor Swift UK       3.32\n5 Taylor Swift US      31.7 \n6 Taylor Swift World   40.8 \n\n\n\nUsing the total album sales, create a percent stacked barchart using ggplot2 of the percentage of sales of studio albums (in millions) along the y-axis for the two artists along the x-axis colored by the country.\n\n\nggplot(sales2,aes(fill=artist, y=total, x=country)) + \n    geom_bar(position=\"fill\", stat=\"identity\") +\n    ggtitle(label = \"ALbum Sales\",\n              subtitle = \"As a Percentage by Artist Seperated by Country\") +\n    xlab(\"Country\") + \n  ylab(\"Precentage of Sales\")+ \n  scale_fill_discrete(name = \"Artist\")"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-1d",
    "href": "DataAnalysisProj1.html#part-1d",
    "title": "Project 1 Data Analysis",
    "section": "Part 1D",
    "text": "Part 1D\nUsing the wrangled data from Part 1A, use ggplot2 to create a bar plot for the sales of studio albums (in millions) along the x-axis for each of the album titles along the y-axis.\nNote:\n\nYou only need to consider the global World sales (you can ignore US and UK sales for this part).\n\n\nsales3 <- sales %>% \n   filter(country == \"World\")\n\n\nThe title of the album must be clearly readable along the y-axis.\nEach bar should be colored by which artist made that album.\nThe bars should be ordered from albums with the most sales (top) to the least sales (bottom) (Note: you must use functions from forcats for this step).\n\n\n#ggplot(sales, aes(fill=artist, y=title, x=sales)) + \n    #geom_bar(position=\"dodge\", stat=\"identity\")\n\nsales3 %>% \n  ggplot(aes(fill = artist, y = fct_reorder(title,\n                         sales), x= sales))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Sales in Millions\", y= \"Album Title\", title=\"Sales in Millions\", subtitle = \"By Album Title and Artist\")+ \n  scale_fill_discrete(name = \"Artist\")+ \n  theme(axis.text.y = element_text(angle = 45))"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-1e",
    "href": "DataAnalysisProj1.html#part-1e",
    "title": "Project 1 Data Analysis",
    "section": "Part 1E",
    "text": "Part 1E\nUsing the wrangled data from Part 1A, use ggplot2 to create a scatter plot of sales of studio albums (in millions) along the y-axis by the released date for each album along the x-axis.\nNote:\n\nThe points should be colored by the artist.\nThere should be three scatter plots (one for UK, US and world sales) faceted by rows.\n\n\n# Add your solution here\nsales %>%\n  filter(country == \"UK\"|country == \"US\"| country == \"World\")%>%\nggplot(aes(x=released, y=sales, color=artist)) +\n  geom_point() + \n  facet_grid(country ~ .)+\n  labs(x=\"Year of Release\", y= \"Sales in Millions\", title=\"Sales in Millions by Year of Release\", subtitle = \"Faceted by Country\", color = \"Artist\")"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-2a",
    "href": "DataAnalysisProj1.html#part-2a",
    "title": "Project 1 Data Analysis",
    "section": "Part 2A",
    "text": "Part 2A\nUsing ts_lyrics, create a new column called line with one line containing the character string for each line of Taylor Swift’s songs.\n\nb_lyrics <- readRDS(here(\"data\",\"b_lyrics.RDS\"))\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(tidytext) \nts_lyrics\n\n# A tibble: 132 × 4\n   Artist       Album        Title                      Lyrics                  \n   <chr>        <chr>        <chr>                      <chr>                   \n 1 Taylor Swift Taylor Swift Tim McGraw                 \"He said the way my blu…\n 2 Taylor Swift Taylor Swift Picture to Burn            \"State the obvious, I d…\n 3 Taylor Swift Taylor Swift Teardrops on my Guitar     \"Drew looks at me,\\nI f…\n 4 Taylor Swift Taylor Swift A Place in This World      \"I don't know what I wa…\n 5 Taylor Swift Taylor Swift Cold As You                \"You have a way of comi…\n 6 Taylor Swift Taylor Swift The Outside                \"I didn't know what I w…\n 7 Taylor Swift Taylor Swift Tied Together With A Smile \"Seems the only one who…\n 8 Taylor Swift Taylor Swift Stay Beautiful             \"Cory's eyes are like a…\n 9 Taylor Swift Taylor Swift Should’ve Said No          \"It's strange to think …\n10 Taylor Swift Taylor Swift Mary’s Song                \"She said\\n\\\"I was seve…\n# … with 122 more rows\n\nb_lyrics\n\n# A tibble: 22,616 × 6\n   line                                  song_id song_…¹ artis…² artis…³ song_…⁴\n   <chr>                                   <dbl> <chr>     <dbl> <chr>     <dbl>\n 1 If I ain't got nothing, I got you       50396 1+1         498 Beyoncé       1\n 2 If I ain't got something, I don't gi…   50396 1+1         498 Beyoncé       2\n 3 'Cause I got it with you                50396 1+1         498 Beyoncé       3\n 4 I don't know much about algebra, but…   50396 1+1         498 Beyoncé       4\n 5 And it's me and you                     50396 1+1         498 Beyoncé       5\n 6 That's all we'll have when the world…   50396 1+1         498 Beyoncé       6\n 7 'Cause baby, we ain't got nothing wi…   50396 1+1         498 Beyoncé       7\n 8 Darling, you got enough for the both…   50396 1+1         498 Beyoncé       8\n 9 So come on, baby, make love to me       50396 1+1         498 Beyoncé       9\n10 When my days look low                   50396 1+1         498 Beyoncé      10\n# … with 22,606 more rows, and abbreviated variable names ¹​song_name,\n#   ²​artist_id, ³​artist_name, ⁴​song_line\n\n\n\nHow many lines in Taylor Swift’s lyrics contain the word “hello”?\n\nFor full credit, show all the rows in ts_lyrics that have “hello” in the line column and report how many rows there are in total."
  },
  {
    "objectID": "DataAnalysisProj1.html#part-2a-1",
    "href": "DataAnalysisProj1.html#part-2a-1",
    "title": "Project 1 Data Analysis",
    "section": "Part 2A",
    "text": "Part 2A\nUsing ts_lyrics, create a new column called line with one line containing the character string for each line of Taylor Swift’s songs.\n\nHow many lines in Taylor Swift’s lyrics contain the word “hello”?\n\nFor full credit, show all the rows in ts_lyrics that have “hello” in the line column and report how many rows there are in total.\n\nHow many lines in Taylor Swift’s lyrics contain the word “goodbye”? For full credit, show all the rows in ts_lyrics that have “goodbye” in the line column and report how many rows there are in total.\n\n\nb_lyrics <- readRDS(here(\"data\",\"b_lyrics.RDS\"))\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(tidytext) \n\n\nts_lyrics_df = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number()) %>%\n    mutate(hello_ind = ifelse(grepl(pattern = \"hello\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(hello_ind == 1) \n    \nts_lyrics_df\n\n# A tibble: 6 × 6\n  Artist       Album    Title                  line              song_…¹ hello…²\n  <chr>        <chr>    <chr>                  <chr>               <int>   <dbl>\n1 Taylor Swift Fearless Love Story             \"And say, \\\"Hell…     932       1\n2 Taylor Swift Red      I Almost Do            \"That I can't sa…    2711       1\n3 Taylor Swift Red      Everything Has Changed \"'Cause all I kn…    3040       1\n4 Taylor Swift Red      Everything Has Changed \"'Cause all I kn…    3059       1\n5 Taylor Swift Red      Everything Has Changed \"All I know is w…    3074       1\n6 Taylor Swift Red      Everything Has Changed \"All I know is w…    3082       1\n# … with abbreviated variable names ¹​song_line, ²​hello_ind\n\nnrow(ts_lyrics_df)\n\n[1] 6\n\n\n\nts_lyrics_df1 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number()) %>%\n    mutate(goodbye_ind = ifelse(grepl(pattern = \"goodbye\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(goodbye_ind == 1) \n    \nts_lyrics_df1\n\n# A tibble: 12 × 6\n   Artist       Album        Title                      line     song_…¹ goodb…²\n   <chr>        <chr>        <chr>                      <chr>      <int>   <dbl>\n 1 Taylor Swift Taylor Swift Tied Together With A Smile \"Goodby…     273       1\n 2 Taylor Swift Speak Now    Mine                       \"Braced…    1457       1\n 3 Taylor Swift Speak Now    Back to December           \"You ga…    1547       1\n 4 Taylor Swift Speak Now    Long Live                  \"And fo…    2154       1\n 5 Taylor Swift Red          I Almost Do                \"And ri…    2712       1\n 6 Taylor Swift Red          Come Back Be Here          \"Stumbl…    3243       1\n 7 Taylor Swift 1989         All You Had to Do Was Stay \"But pe…    3639       1\n 8 Taylor Swift reputation   Getaway Car                \"Said g…    4908       1\n 9 Taylor Swift reputation   Getaway Car                \"Said g…    4916       1\n10 Taylor Swift Lover        Death By A Thousand Cuts   \"Saying…    5817       1\n11 Taylor Swift Lover        Death By A Thousand Cuts   \"'Cause…    5837       1\n12 Taylor Swift Lover        Daylight                   \"I'll t…    6222       1\n# … with abbreviated variable names ¹​song_line, ²​goodbye_ind\n\nnrow(ts_lyrics_df1)\n\n[1] 12\n\n\nTHIS IS CODE CHUNK IS JUST FOR MY OWN LEARNING PLEASE DO NOT GRADE\nts_lyrics_df = tibble(text = ts_lyrics$Lyrics)\nts_lyrics_df <- ts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) ts_lyrics_df\nts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) %>% mutate(hello_ind = ifelse(grepl(pattern = “hello”, x = line, ignore.case = TRUE),1,0)) %>% filter(hello_ind == 1)\nts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) %>% mutate(hello_ind = ifelse(grepl(pattern = “hello”, x = line, ignore.case = TRUE),1,0)) %>% filter(hello_ind == 1) %>% summarise(sum_hello = sum(hello_ind))\nts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) %>% mutate(goodbye_ind = ifelse(grepl(pattern = “goodbye”, x = line, ignore.case = TRUE),1,0)) %>% filter(goodbye_ind == 1)\nts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) %>% mutate(goodbye_ind = ifelse(grepl(pattern = “goodbye”, x = line, ignore.case = TRUE),1,0)) %>% filter(goodbye_ind == 1) %>% summarise(sum_goodbye = sum(goodbye_ind))"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-2b",
    "href": "DataAnalysisProj1.html#part-2b",
    "title": "Project 1 Data Analysis",
    "section": "Part 2B",
    "text": "Part 2B\nRepeat the same analysis for b_lyrics as described in Part 2A.\n\nb_lyrics_df = b_lyrics %>%\n    mutate(hello_ind = ifelse(grepl(pattern = \"hello\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(hello_ind == 1) \n    \nb_lyrics_df\n\n# A tibble: 91 × 7\n   line                          song_id song_…¹ artis…² artis…³ song_…⁴ hello…⁵\n   <chr>                           <dbl> <chr>     <dbl> <chr>     <dbl>   <dbl>\n 1 Hello world, well I just bou… 2220711 \"Dream…     498 Beyoncé       5       1\n 2 Hello Stevie, How you feeling 1981227 \"Finge…     498 Beyoncé       6       1\n 3 Fellow great Americans, hello 2715227 \"FREED…     498 Beyoncé      52       1\n 4 You had me at hello (Hello)     80249 \"Hello\"     498 Beyoncé      15       1\n 5 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      16       1\n 6 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      17       1\n 7 You had me at hello (Hello)     80249 \"Hello\"     498 Beyoncé      18       1\n 8 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      19       1\n 9 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      20       1\n10 'Cause you had me at hello (…   80249 \"Hello\"     498 Beyoncé      24       1\n# … with 81 more rows, and abbreviated variable names ¹​song_name, ²​artist_id,\n#   ³​artist_name, ⁴​song_line, ⁵​hello_ind\n\nnrow(b_lyrics_df)\n\n[1] 91\n\n\n\nb_lyrics_df1 = b_lyrics %>%\n    mutate(goodbye_ind = ifelse(grepl(pattern = \"goodbye\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(goodbye_ind == 1) \n    \nb_lyrics_df1\n\n# A tibble: 12 × 7\n   line                          song_id song_…¹ artis…² artis…³ song_…⁴ goodb…⁵\n   <chr>                           <dbl> <chr>     <dbl> <chr>     <dbl>   <dbl>\n 1 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      12       1\n 2 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      21       1\n 3 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      24       1\n 4 Thank God, I found the good …   51492 Best T…     498 Beyoncé      38       1\n 5 Thank God, I found the good … 1946060 Best T…     498 Beyoncé      42       1\n 6 Thank God, I found the good … 4241137 Best T…     498 Beyoncé      38       1\n 7 It's so hard to say goodbye    435491 Gift f…     498 Beyoncé      23       1\n 8 I never want to say goodbye    435491 Gift f…     498 Beyoncé      24       1\n 9 I never, ever want to say go…  435491 Gift f…     498 Beyoncé      25       1\n10 We've got to say goodbye      1844620 Hard T…     498 Beyoncé      29       1\n11 Don't have to say goodbye     1224115 Slow L…     498 Beyoncé      42       1\n12 Somewhere between hi and goo…  141848 Yes         498 Beyoncé      27       1\n# … with abbreviated variable names ¹​song_name, ²​artist_id, ³​artist_name,\n#   ⁴​song_line, ⁵​goodbye_ind\n\nnrow(b_lyrics_df1)\n\n[1] 12"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-2c",
    "href": "DataAnalysisProj1.html#part-2c",
    "title": "Project 1 Data Analysis",
    "section": "Part 2C",
    "text": "Part 2C\nUsing the b_lyrics dataset,\n\nTokenize each lyrical line by words.\nRemove the “stopwords”.\nCalculate the total number for each word in the lyrics.\nUsing the “bing” sentiment lexicon, add a column to the summarized data frame adding the “bing” sentiment lexicon.\nSort the rows from most frequent to least frequent words.\nOnly keep the top 25 most frequent words.\nAuto print the wrangled tibble data frame.\nUse ggplot2 to create a bar plot with the top words on the y-axis and the frequency of each word on the x-axis. Color each bar by the sentiment of each word from the “bing” sentiment lexicon. Bars should be ordered from most frequent on the top to least frequent on the bottom of the plot.\nCreate a word cloud of the top 25 most frequent words.\n\n\nb_lyrics_df2 = tibble(text = b_lyrics$line) \n\nb_lyrics_df2n <- b_lyrics_df2 %>% \n unnest_tokens(output = word, \n                input = text, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nb_lyrics_df2n\n\n# A tibble: 5,937 × 2\n   word      n\n   <chr> <int>\n 1 love   1362\n 2 baby   1024\n 3 girl    592\n 4 wanna   564\n 5 hey     499\n 6 boy     494\n 7 yeah    491\n 8 feel    488\n 9 time    452\n10 uh      408\n# … with 5,927 more rows\n\nb_lyrics_df2n <- b_lyrics_df2n %>%\ninner_join(get_sentiments(\"bing\"))%>%                                 \n  slice(1:25)\n\nJoining, by = \"word\"\n\nb_lyrics_df2n\n\n# A tibble: 25 × 3\n   word          n sentiment\n   <chr>     <int> <chr>    \n 1 love       1362 positive \n 2 crazy       308 negative \n 3 top         241 positive \n 4 bad         132 negative \n 5 beautiful   131 positive \n 6 whoa        121 positive \n 7 damn        106 negative \n 8 hurt         90 negative \n 9 hard         87 negative \n10 ready        85 positive \n# … with 15 more rows\n\n\n\nb_lyrics_df2n %>% \n  slice(1:25) %>% \n  ggplot(aes(fill = sentiment, y = fct_reorder(word,\n                         n), x= n))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Frequency of Word\", y= \"Sentiment Word\", title=\"Sentiment Word Frequency\")+ \n  scale_fill_discrete(name = \"Sentiment\")\n\n\n\n\n\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\nb_lyrics_df2n %>% \n  slice(1:25) %>% \n  with(wordcloud(word, n))"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-2d",
    "href": "DataAnalysisProj1.html#part-2d",
    "title": "Project 1 Data Analysis",
    "section": "Part 2D",
    "text": "Part 2D\nRepeat the same analysis as above in Part 2C, but for ts_lyrics.\n\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nts_lyrics1 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number())\n\nts_lyrics_df2 = tibble(text = ts_lyrics1$line) \n\nts_lyrics_df2 <- ts_lyrics_df2 %>% \n unnest_tokens(output = word, \n                input = text, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nts_lyrics_df2\n\n# A tibble: 2,579 × 2\n   word      n\n   <chr> <int>\n 1 love    248\n 2 time    225\n 3 wanna   158\n 4 baby    153\n 5 ooh     127\n 6 yeah    105\n 7 stay    100\n 8 gonna    98\n 9 night    96\n10 bad      80\n# … with 2,569 more rows\n\nts_lyrics_df2 <- ts_lyrics_df2 %>%\ninner_join(get_sentiments(\"bing\"))%>%                                 \n  slice(1:25)\n\nJoining, by = \"word\"\n\nts_lyrics_df2\n\n# A tibble: 25 × 3\n   word          n sentiment\n   <chr>     <int> <chr>    \n 1 love        248 positive \n 2 bad          80 negative \n 3 shake        73 negative \n 4 break        59 negative \n 5 mad          48 negative \n 6 beautiful    46 positive \n 7 smile        45 positive \n 8 hate         44 negative \n 9 fall         43 negative \n10 whoa         36 positive \n# … with 15 more rows\n\n\n\nts_lyrics_df2 %>% \n  slice(1:25) %>% \n  ggplot(aes(fill = sentiment, y = fct_reorder(word,\n                         n), x= n))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Frequency of Word\", y= \"Sentiment Word\", title=\"Sentiment Word Frequency\", subtitle = \"Categorized by negative and positive sentiments\")+ \n  scale_fill_discrete(name = \"Sentiment\")\n\n\n\n\n\nlibrary(wordcloud)\nts_lyrics_df2 %>% \n  slice(1:25) %>% \n  with(wordcloud(word, n))"
  },
  {
    "objectID": "DataAnalysisProj1.html#part-2e",
    "href": "DataAnalysisProj1.html#part-2e",
    "title": "Project 1 Data Analysis",
    "section": "Part 2E",
    "text": "Part 2E\nUsing the ts_lyrics dataset,\n\nTokenize each lyrical line by words.\nRemove the “stopwords”.\nCalculate the total number for each word in the lyrics for each Album.\nUsing the “afinn” sentiment lexicon, add a column to the summarized data frame adding the “afinn” sentiment lexicon.\nCalculate the average sentiment score for each Album.\nAuto print the wrangled tibble data frame.\n\n\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(textdata)\n\n\nts_lyrics2 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) \n\nts_lyrics_df3 = tibble(Album = ts_lyrics2$Album, line= ts_lyrics2$line) \nts_lyrics_df3 <- ts_lyrics_df3 %>% \n  group_by(Album)\nts_lyrics_df3\n\n# A tibble: 7,168 × 2\n# Groups:   Album [8]\n   Album        line                                                       \n   <chr>        <chr>                                                      \n 1 Taylor Swift \"He said the way my blue eyes shinx\"                       \n 2 Taylor Swift \"Put those Georgia stars to shame that night\"              \n 3 Taylor Swift \"I said: \\\"That's a lie.\\\"\"                                \n 4 Taylor Swift \"Just a boy in a Chevy truck\"                              \n 5 Taylor Swift \"That had a tendency of gettin' stuck\"                     \n 6 Taylor Swift \"On back roads at night\"                                   \n 7 Taylor Swift \"And I was right there beside him all summer long\"         \n 8 Taylor Swift \"And then the time we woke up to find that summer had gone\"\n 9 Taylor Swift \"But when you think \\\"Tim McGraw\\\"\"                        \n10 Taylor Swift \"I hope you think my favorite song\"                        \n# … with 7,158 more rows\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \n unnest_tokens(output = word, \n                input = line, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nts_lyrics_df3\n\n# A tibble: 4,968 × 3\n# Groups:   Album [8]\n   Album word         n\n   <chr> <chr>    <int>\n 1 1989  love        82\n 2 1989  shake       70\n 3 Red   time        66\n 4 Lover ooh         61\n 5 Red   uh          50\n 6 Red   red         46\n 7 Lover love        44\n 8 Lover wanna       42\n 9 1989  baby        41\n10 Lover daylight    40\n# … with 4,958 more rows\n\n\n\nJoin the wrangled data frame from Part 1A (album sales in millions) with the wrangled data frame from #6 above (average sentiment score for each album).\n\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \ninner_join(get_sentiments(\"afinn\")) \n\nJoining, by = \"word\"\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \n  group_by(Album)%>%\n  summarise(average = mean(value))\nts_lyrics_df3\n\n# A tibble: 8 × 2\n  Album         average\n  <chr>           <dbl>\n1 1989         -0.822  \n2 Fearless      0.0192 \n3 folklore     -0.613  \n4 Lover        -0.429  \n5 Red          -0.00870\n6 reputation   -0.495  \n7 Speak Now    -0.365  \n8 Taylor Swift  0.137  \n\n\n\nsalesdf <- salesdf %>%\n  rename(Album = title)\n\n\nsalesdf\n\n# A tibble: 36 × 8\n   artist       Album        country  sales released   re_release  label formats\n   <chr>        <chr>        <fct>    <dbl> <date>     <chr>       <chr> <chr>  \n 1 Taylor Swift Taylor Swift US       5.72  2006-10-24 March 18, … Big … CD, CD…\n 2 Taylor Swift Fearless     World   12     2008-11-11 October 27… Big … CD, CD…\n 3 Taylor Swift Fearless     US       7.18  2008-11-11 October 27… Big … CD, CD…\n 4 Taylor Swift Fearless     UK       0.609 2008-11-11 October 27… Big … CD, CD…\n 5 Taylor Swift Speak Now    World    5     2010-10-25 <NA>        Big … CD, CD…\n 6 Taylor Swift Speak Now    US       4.69  2010-10-25 <NA>        Big … CD, CD…\n 7 Taylor Swift Speak Now    UK       0.169 2010-10-25 <NA>        Big … CD, CD…\n 8 Taylor Swift Red          World    6     2012-10-22 <NA>        Big … CD, CD…\n 9 Taylor Swift Red          US       4.46  2012-10-22 <NA>        Big … CD, CD…\n10 Taylor Swift Red          UK       0.693 2012-10-22 <NA>        Big … CD, CD…\n# … with 26 more rows\n\nts_lyrics_df3\n\n# A tibble: 8 × 2\n  Album         average\n  <chr>           <dbl>\n1 1989         -0.822  \n2 Fearless      0.0192 \n3 folklore     -0.613  \n4 Lover        -0.429  \n5 Red          -0.00870\n6 reputation   -0.495  \n7 Speak Now    -0.365  \n8 Taylor Swift  0.137  \n\ndataf <- inner_join(ts_lyrics_df3, salesdf, 'Album')\ndataf\n\n# A tibble: 16 × 9\n   Album         average artist  country  sales released   re_re…¹ label formats\n   <chr>           <dbl> <chr>   <fct>    <dbl> <date>     <chr>   <chr> <chr>  \n 1 1989         -0.822   Taylor… World   10.1   2014-10-27 <NA>    Big … CD, CD…\n 2 1989         -0.822   Taylor… US       6.22  2014-10-27 <NA>    Big … CD, CD…\n 3 1989         -0.822   Taylor… UK       1.25  2014-10-27 <NA>    Big … CD, CD…\n 4 Fearless      0.0192  Taylor… World   12     2008-11-11 Octobe… Big … CD, CD…\n 5 Fearless      0.0192  Taylor… US       7.18  2008-11-11 Octobe… Big … CD, CD…\n 6 Fearless      0.0192  Taylor… UK       0.609 2008-11-11 Octobe… Big … CD, CD…\n 7 Lover        -0.429   Taylor… World    3.2   2019-08-23 <NA>    Repu… CD, LP…\n 8 Lover        -0.429   Taylor… US       1.08  2019-08-23 <NA>    Repu… CD, LP…\n 9 Lover        -0.429   Taylor… UK       0.222 2019-08-23 <NA>    Repu… CD, LP…\n10 Red          -0.00870 Taylor… World    6     2012-10-22 <NA>    Big … CD, CD…\n11 Red          -0.00870 Taylor… US       4.46  2012-10-22 <NA>    Big … CD, CD…\n12 Red          -0.00870 Taylor… UK       0.693 2012-10-22 <NA>    Big … CD, CD…\n13 Speak Now    -0.365   Taylor… World    5     2010-10-25 <NA>    Big … CD, CD…\n14 Speak Now    -0.365   Taylor… US       4.69  2010-10-25 <NA>    Big … CD, CD…\n15 Speak Now    -0.365   Taylor… UK       0.169 2010-10-25 <NA>    Big … CD, CD…\n16 Taylor Swift  0.137   Taylor… US       5.72  2006-10-24 March … Big … CD, CD…\n# … with abbreviated variable name ¹​re_release\n\n\n\nUsing ggplot2, create a scatter plot of the average sentiment score for each album (y-axis) and the album release data along the x-axis. Make the size of each point the album sales in millions.\nAdd a horizontal line at y-intercept=0.\nWrite 2-3 sentences interpreting the plot answering the question “How has the sentiment of Taylor Swift’s albums have changed over time?”. Add a title, subtitle, and useful axis labels.\n\n\ndataf %>%\nggplot(aes(x=released, y=average, color=Album, size = sales)) +\n  geom_point() + \n  geom_hline(yintercept=0, linetype=\"dashed\", color = \"red\")+\n  labs(x=\"Year of Release\", y= \"Average Sentiment Score\", title=\"Average sentiment Score by Year of Release\", subtitle = \"Averages Grouped by Album\", color = \"Album\", size = \"Sales in Millions\")\n\n\n\n\nWrite 2-3 sentences interpreting the plot answering the question “How has the sentiment of Taylor Swift’s albums have changed over time?”.\n\nConclusion\nThe sentiment of Taylor’s albums have gotten more negative over time, as we can see the very first album has the highest positive average score. Positivity rebounded a bit after being at its lowest with the album 1989. Sales seemed to not be affected by change in sentiment and is likely correlated with some other variable. However, most albums have more negative average sentiment than positive, as most albums fall below the 0 line, where positivity and negativity are equal."
  },
  {
    "objectID": "DataAnalysisProj1_final.html",
    "href": "DataAnalysisProj1_final.html",
    "title": "Data Analysis Project",
    "section": "",
    "text": "Intended Audience\nThis was a homework for 140.776 Statistical Computing in fall 2022. This could be useful for the general public that is interested in studying album sales of artists and their possible relation to the lyrics in the songs on the albums.\n (Fekadu 2019)\n\n\nData\nThe datasets for this part of the assignment comes from TidyTuesday.\nData dictionary avaialble here:\n\nhttps://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-09-29\n\n\nb_lyrics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/beyonce_lyrics.csv')\nts_lyrics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/taylor_swift_lyrics.csv')\nsales <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/sales.csv')\n\n\nlibrary(here)\nif(!file.exists(here(\"data\",\"b_lyrics.RDS\"))){\n  b_lyrics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/beyonce_lyrics.csv')\n  ts_lyrics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/taylor_swift_lyrics.csv')\n  sales <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/sales.csv')\n  \n  # save the files to RDS objects\n  saveRDS(b_lyrics, file = here(\"data\",\"b_lyrics.RDS\"))\n  saveRDS(ts_lyrics, file = here(\"data\",\"ts_lyrics.RDS\"))\n  saveRDS(sales, file = here(\"data\",\"sales.RDS\"))\n}\n\n\nb_lyrics <- readRDS(here(\"data\",\"b_lyrics.RDS\"))\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nsales <- readRDS(here(\"data\",\"sales.RDS\"))\n\n\n\nData Wrangling\n\n# Use `lubridate` to create a column called `released` that is a `Date` class. However, to be able to do this, you first need to use `stringr` to search for pattern that matches things like this \"(US)\\[51\\]\" in a string like this \"September 1, 2006 (US)\\[51\\]\" and removes them. (**Note**: to get full credit, you must create the regular expression).\n\n# Use `forcats` to create a factor called `country` (**Note**: you may need to collapse some factor levels).\n\nsales <- readRDS(here(\"data\",\"sales.RDS\"))\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(stringr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nsales$released <- str_remove_all(string=sales$released, pattern = \"(US)|(UK)|[\\\\[\\\\]\\\\(\\\\)]|(39)|(51)\")\n\nsales <- sales %>% \n  mutate(released=mdy(released)) %>% \n  mutate(country = as.factor(country)) %>%\n  mutate(country = fct_collapse(country,\n  World = c(\"WW\", \"World\"),\n  FR = c(\"FR\", \"FRA\")\n))\n\n\n#Transform the `sales` into a unit that is album sales in millions of dollars.\nsales$sales <-  as.numeric(sales$sales)/1000000\n\n\n#Keep only album sales from the UK, the US or the World.\n#Auto print your final wrangled tibble data frame.\nsalesdf <- sales %>% \n   filter(country == \"UK\"|country == \"US\"| country == \"World\")\nsalesdf\n\n# A tibble: 36 × 8\n   artist       title        country  sales released   re_release  label formats\n   <chr>        <chr>        <fct>    <dbl> <date>     <chr>       <chr> <chr>  \n 1 Taylor Swift Taylor Swift US       5.72  2006-10-24 March 18, … Big … CD, CD…\n 2 Taylor Swift Fearless     World   12     2008-11-11 October 27… Big … CD, CD…\n 3 Taylor Swift Fearless     US       7.18  2008-11-11 October 27… Big … CD, CD…\n 4 Taylor Swift Fearless     UK       0.609 2008-11-11 October 27… Big … CD, CD…\n 5 Taylor Swift Speak Now    World    5     2010-10-25 <NA>        Big … CD, CD…\n 6 Taylor Swift Speak Now    US       4.69  2010-10-25 <NA>        Big … CD, CD…\n 7 Taylor Swift Speak Now    UK       0.169 2010-10-25 <NA>        Big … CD, CD…\n 8 Taylor Swift Red          World    6     2012-10-22 <NA>        Big … CD, CD…\n 9 Taylor Swift Red          US       4.46  2012-10-22 <NA>        Big … CD, CD…\n10 Taylor Swift Red          UK       0.693 2012-10-22 <NA>        Big … CD, CD…\n# … with 26 more rows\n\n\nIn this section, we will do some more data wrangling followed by summarization using wrangled data from Part 1A.\n\n# Keep only album sales from the US.\nsales1 <- sales %>% \n   filter(country == \"US\")\n\n\n#Create a new column called `years_since_release` corresponding to the number of years since the release of each album from Beyoncé and Taylor Swift. This should be a whole number and you should round down to \"14\" if you get a non-whole number like \"14.12\" years. (**Hint**: you may find the `interval()` function from `lubridate` helpful here, but this is not the only way to do this.)\nsales1 <- sales %>% \n    mutate(years_since_release=(year(Sys.Date())-year(released)))\n\n\n#Calculate the most recent, oldest, and the median years since albums were released for both Beyoncé and Taylor Swift.\nsales1 %>% \n  filter(artist==\"Taylor Swift\")%>%\n  summarize(median = median(years_since_release),\n            recent = min(years_since_release), \n            oldest = max(years_since_release))\n\n# A tibble: 1 × 3\n  median recent oldest\n   <dbl>  <dbl>  <dbl>\n1      8      2     16\n\nsales1 %>% \n  filter(artist==\"Beyoncé\")%>%\n  summarize(median = median(years_since_release),\n            recent = min(years_since_release), \n            oldest = max(years_since_release))\n\n# A tibble: 1 × 3\n  median recent oldest\n   <dbl>  <dbl>  <dbl>\n1   12.5      6     19\n\n\n\n#Calculate the total album sales for each artist and for each `country` (only sales from the UK, US, and World).\nsales2 <- sales %>% \n  filter(country == \"UK\"|country == \"US\"| country == \"World\")%>%\n  group_by(artist, country) %>%\n  summarize(total = sum(sales))\n\n`summarise()` has grouped output by 'artist'. You can override using the\n`.groups` argument.\n\nsales2\n\n# A tibble: 6 × 3\n# Groups:   artist [2]\n  artist       country total\n  <chr>        <fct>   <dbl>\n1 Beyoncé      UK       5.24\n2 Beyoncé      US      17.7 \n3 Beyoncé      World   34.5 \n4 Taylor Swift UK       3.32\n5 Taylor Swift US      31.7 \n6 Taylor Swift World   40.8 \n\n\n\n\nPlots\n\n#Using the total album sales, create a [percent stacked barchart](https://r-graph-gallery.com/48-grouped-barplot-with-ggplot2) using `ggplot2` of the percentage of sales of studio albums (in millions) along the y-axis for the two artists along the x-axis colored by the `country`.\nggplot(sales2,aes(fill=artist, y=total, x=country)) + \n    geom_bar(position=\"fill\", stat=\"identity\") +\n    ggtitle(label = \"ALbum Sales\",\n              subtitle = \"As a Percentage by Artist Seperated by Country\") +\n    xlab(\"Country\") + \n  ylab(\"Precentage of Sales\")+ \n  scale_fill_discrete(name = \"Artist\")\n\n\n\n\n\nknitr::kable(\n  sales2[1:6, 1:3]\n)\n\n\n\n\n\n\nartist\ncountry\ntotal\n\n\n\n\nBeyoncé\nUK\n5.237000\n\n\nBeyoncé\nUS\n17.656000\n\n\nBeyoncé\nWorld\n34.500000\n\n\nTaylor Swift\nUK\n3.320935\n\n\nTaylor Swift\nUS\n31.659000\n\n\nTaylor Swift\nWorld\n40.800000\n\n\n\nFigure 1: Sales in the US, UK and World for Swift and Beyonce\n\n\n\n#Using the wrangled data from Part 1A, use `ggplot2` to create a bar plot for the sales of studio albums (in millions) along the x-axis for each of the album titles along the y-axis.\nsales3 <- sales %>% \n   filter(country == \"World\")\n\n\n#ggplot(sales, aes(fill=artist, y=title, x=sales)) + \n    #geom_bar(position=\"dodge\", stat=\"identity\")\n\nsales3 %>% \n  ggplot(aes(fill = artist, y = fct_reorder(title,\n                         sales), x= sales))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Sales in Millions\", y= \"Album Title\", title=\"Sales in Millions\", subtitle = \"By Album Title and Artist\")+ \n  scale_fill_discrete(name = \"Artist\")+ \n  theme(axis.text.y = element_text(angle = 45))\n\n\n\n\n\n#Using the wrangled data from Part 1A, use `ggplot2` to create a scatter plot of sales of studio albums (in millions) along the y-axis by the released date for each album along the x-axis.\n\nsales %>%\n  filter(country == \"UK\"|country == \"US\"| country == \"World\")%>%\nggplot(aes(x=released, y=sales, color=artist)) +\n  geom_point() + \n  facet_grid(country ~ .)+\n  labs(x=\"Year of Release\", y= \"Sales in Millions\", title=\"Sales in Millions by Year of Release\", subtitle = \"Faceted by Country\", color = \"Artist\")\n\n\n\n\n\n\nExploring sentiment of lyrics\n\n#Using `ts_lyrics`, create a new column called `line` with one line containing the character string for each line of Taylor Swift's songs.\n\nb_lyrics <- readRDS(here(\"data\",\"b_lyrics.RDS\"))\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(tidytext) \nts_lyrics\n\n# A tibble: 132 × 4\n   Artist       Album        Title                      Lyrics                  \n   <chr>        <chr>        <chr>                      <chr>                   \n 1 Taylor Swift Taylor Swift Tim McGraw                 \"He said the way my blu…\n 2 Taylor Swift Taylor Swift Picture to Burn            \"State the obvious, I d…\n 3 Taylor Swift Taylor Swift Teardrops on my Guitar     \"Drew looks at me,\\nI f…\n 4 Taylor Swift Taylor Swift A Place in This World      \"I don't know what I wa…\n 5 Taylor Swift Taylor Swift Cold As You                \"You have a way of comi…\n 6 Taylor Swift Taylor Swift The Outside                \"I didn't know what I w…\n 7 Taylor Swift Taylor Swift Tied Together With A Smile \"Seems the only one who…\n 8 Taylor Swift Taylor Swift Stay Beautiful             \"Cory's eyes are like a…\n 9 Taylor Swift Taylor Swift Should’ve Said No          \"It's strange to think …\n10 Taylor Swift Taylor Swift Mary’s Song                \"She said\\n\\\"I was seve…\n# … with 122 more rows\n\nb_lyrics\n\n# A tibble: 22,616 × 6\n   line                                  song_id song_…¹ artis…² artis…³ song_…⁴\n   <chr>                                   <dbl> <chr>     <dbl> <chr>     <dbl>\n 1 If I ain't got nothing, I got you       50396 1+1         498 Beyoncé       1\n 2 If I ain't got something, I don't gi…   50396 1+1         498 Beyoncé       2\n 3 'Cause I got it with you                50396 1+1         498 Beyoncé       3\n 4 I don't know much about algebra, but…   50396 1+1         498 Beyoncé       4\n 5 And it's me and you                     50396 1+1         498 Beyoncé       5\n 6 That's all we'll have when the world…   50396 1+1         498 Beyoncé       6\n 7 'Cause baby, we ain't got nothing wi…   50396 1+1         498 Beyoncé       7\n 8 Darling, you got enough for the both…   50396 1+1         498 Beyoncé       8\n 9 So come on, baby, make love to me       50396 1+1         498 Beyoncé       9\n10 When my days look low                   50396 1+1         498 Beyoncé      10\n# … with 22,606 more rows, and abbreviated variable names ¹​song_name,\n#   ²​artist_id, ³​artist_name, ⁴​song_line\n\n\n\n#Using `ts_lyrics`, create a new column called `line` with one line containing the character string for each line of Taylor Swift's songs.\n\n#For full credit, show all the rows in `ts_lyrics` that have \"hello\" in the `line` column and report how many rows there are in total.\n\n#How many lines in Taylor Swift's lyrics contain the word \"goodbye\"? For full credit, show all the rows in `ts_lyrics` that have \"goodbye\" in the `line` column and report how many rows there are in total.\n\nb_lyrics <- readRDS(here(\"data\",\"b_lyrics.RDS\"))\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(tidytext) \n\n\nts_lyrics_df = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number()) %>%\n    mutate(hello_ind = ifelse(grepl(pattern = \"hello\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(hello_ind == 1) \n    \nts_lyrics_df\n\n# A tibble: 6 × 6\n  Artist       Album    Title                  line              song_…¹ hello…²\n  <chr>        <chr>    <chr>                  <chr>               <int>   <dbl>\n1 Taylor Swift Fearless Love Story             \"And say, \\\"Hell…     932       1\n2 Taylor Swift Red      I Almost Do            \"That I can't sa…    2711       1\n3 Taylor Swift Red      Everything Has Changed \"'Cause all I kn…    3040       1\n4 Taylor Swift Red      Everything Has Changed \"'Cause all I kn…    3059       1\n5 Taylor Swift Red      Everything Has Changed \"All I know is w…    3074       1\n6 Taylor Swift Red      Everything Has Changed \"All I know is w…    3082       1\n# … with abbreviated variable names ¹​song_line, ²​hello_ind\n\nnrow(ts_lyrics_df)\n\n[1] 6\n\n\n\nts_lyrics_df1 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number()) %>%\n    mutate(goodbye_ind = ifelse(grepl(pattern = \"goodbye\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(goodbye_ind == 1) \n    \nts_lyrics_df1\n\n# A tibble: 12 × 6\n   Artist       Album        Title                      line     song_…¹ goodb…²\n   <chr>        <chr>        <chr>                      <chr>      <int>   <dbl>\n 1 Taylor Swift Taylor Swift Tied Together With A Smile \"Goodby…     273       1\n 2 Taylor Swift Speak Now    Mine                       \"Braced…    1457       1\n 3 Taylor Swift Speak Now    Back to December           \"You ga…    1547       1\n 4 Taylor Swift Speak Now    Long Live                  \"And fo…    2154       1\n 5 Taylor Swift Red          I Almost Do                \"And ri…    2712       1\n 6 Taylor Swift Red          Come Back Be Here          \"Stumbl…    3243       1\n 7 Taylor Swift 1989         All You Had to Do Was Stay \"But pe…    3639       1\n 8 Taylor Swift reputation   Getaway Car                \"Said g…    4908       1\n 9 Taylor Swift reputation   Getaway Car                \"Said g…    4916       1\n10 Taylor Swift Lover        Death By A Thousand Cuts   \"Saying…    5817       1\n11 Taylor Swift Lover        Death By A Thousand Cuts   \"'Cause…    5837       1\n12 Taylor Swift Lover        Daylight                   \"I'll t…    6222       1\n# … with abbreviated variable names ¹​song_line, ²​goodbye_ind\n\nnrow(ts_lyrics_df1)\n\n[1] 12\n\n\n\nb_lyrics_df = b_lyrics %>%\n    mutate(hello_ind = ifelse(grepl(pattern = \"hello\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(hello_ind == 1) \n    \nb_lyrics_df\n\n# A tibble: 91 × 7\n   line                          song_id song_…¹ artis…² artis…³ song_…⁴ hello…⁵\n   <chr>                           <dbl> <chr>     <dbl> <chr>     <dbl>   <dbl>\n 1 Hello world, well I just bou… 2220711 \"Dream…     498 Beyoncé       5       1\n 2 Hello Stevie, How you feeling 1981227 \"Finge…     498 Beyoncé       6       1\n 3 Fellow great Americans, hello 2715227 \"FREED…     498 Beyoncé      52       1\n 4 You had me at hello (Hello)     80249 \"Hello\"     498 Beyoncé      15       1\n 5 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      16       1\n 6 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      17       1\n 7 You had me at hello (Hello)     80249 \"Hello\"     498 Beyoncé      18       1\n 8 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      19       1\n 9 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      20       1\n10 'Cause you had me at hello (…   80249 \"Hello\"     498 Beyoncé      24       1\n# … with 81 more rows, and abbreviated variable names ¹​song_name, ²​artist_id,\n#   ³​artist_name, ⁴​song_line, ⁵​hello_ind\n\nnrow(b_lyrics_df)\n\n[1] 91\n\n\n\nb_lyrics_df1 = b_lyrics %>%\n    mutate(goodbye_ind = ifelse(grepl(pattern = \"goodbye\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(goodbye_ind == 1) \n    \nb_lyrics_df1\n\n# A tibble: 12 × 7\n   line                          song_id song_…¹ artis…² artis…³ song_…⁴ goodb…⁵\n   <chr>                           <dbl> <chr>     <dbl> <chr>     <dbl>   <dbl>\n 1 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      12       1\n 2 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      21       1\n 3 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      24       1\n 4 Thank God, I found the good …   51492 Best T…     498 Beyoncé      38       1\n 5 Thank God, I found the good … 1946060 Best T…     498 Beyoncé      42       1\n 6 Thank God, I found the good … 4241137 Best T…     498 Beyoncé      38       1\n 7 It's so hard to say goodbye    435491 Gift f…     498 Beyoncé      23       1\n 8 I never want to say goodbye    435491 Gift f…     498 Beyoncé      24       1\n 9 I never, ever want to say go…  435491 Gift f…     498 Beyoncé      25       1\n10 We've got to say goodbye      1844620 Hard T…     498 Beyoncé      29       1\n11 Don't have to say goodbye     1224115 Slow L…     498 Beyoncé      42       1\n12 Somewhere between hi and goo…  141848 Yes         498 Beyoncé      27       1\n# … with abbreviated variable names ¹​song_name, ²​artist_id, ³​artist_name,\n#   ⁴​song_line, ⁵​goodbye_ind\n\nnrow(b_lyrics_df1)\n\n[1] 12\n\n\n\n#Using the `b_lyrics` dataset,\n\n#Tokenize each lyrical line by words.\n#Remove the \"stopwords\".\n#Calculate the total number for each word in the lyrics.\n#Using the \"bing\" sentiment lexicon, add a column to the summarized data frame adding the \"bing\" sentiment lexicon.\n#Sort the rows from most frequent to least frequent words.\n#Only keep the top 25 most frequent words.\n#Auto print the wrangled tibble data frame.\n#Use `ggplot2` to create a bar plot with the top words on the y-axis and the frequency of each word on the x-axis. Color each bar by the sentiment of each word from the \"bing\" sentiment lexicon. Bars should be ordered from most frequent on the top to least frequent on the bottom of the plot.\n#Create a word cloud of the top 25 most frequent words.\n\nb_lyrics_df2 = tibble(text = b_lyrics$line) \n\nb_lyrics_df2n <- b_lyrics_df2 %>% \n unnest_tokens(output = word, \n                input = text, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nb_lyrics_df2n\n\n# A tibble: 5,937 × 2\n   word      n\n   <chr> <int>\n 1 love   1362\n 2 baby   1024\n 3 girl    592\n 4 wanna   564\n 5 hey     499\n 6 boy     494\n 7 yeah    491\n 8 feel    488\n 9 time    452\n10 uh      408\n# … with 5,927 more rows\n\nb_lyrics_df2n <- b_lyrics_df2n %>%\ninner_join(get_sentiments(\"bing\"))%>%                                 \n  slice(1:25)\n\nJoining, by = \"word\"\n\nb_lyrics_df2n\n\n# A tibble: 25 × 3\n   word          n sentiment\n   <chr>     <int> <chr>    \n 1 love       1362 positive \n 2 crazy       308 negative \n 3 top         241 positive \n 4 bad         132 negative \n 5 beautiful   131 positive \n 6 whoa        121 positive \n 7 damn        106 negative \n 8 hurt         90 negative \n 9 hard         87 negative \n10 ready        85 positive \n# … with 15 more rows\n\n\n\nb_lyrics_df2n %>% \n  slice(1:25) %>% \n  ggplot(aes(fill = sentiment, y = fct_reorder(word,\n                         n), x= n))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Frequency of Word\", y= \"Sentiment Word\", title=\"Sentiment Word Frequency\")+ \n  scale_fill_discrete(name = \"Sentiment\")\n\n\n\n\n\n\nWordcloud\n\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\nb_lyrics_df2n %>% \n  slice(1:25) %>% \n  with(wordcloud(word, n))\n\n\n\n\n\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nts_lyrics1 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number())\n\nts_lyrics_df2 = tibble(text = ts_lyrics1$line) \n\nts_lyrics_df2 <- ts_lyrics_df2 %>% \n unnest_tokens(output = word, \n                input = text, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nts_lyrics_df2\n\n# A tibble: 2,579 × 2\n   word      n\n   <chr> <int>\n 1 love    248\n 2 time    225\n 3 wanna   158\n 4 baby    153\n 5 ooh     127\n 6 yeah    105\n 7 stay    100\n 8 gonna    98\n 9 night    96\n10 bad      80\n# … with 2,569 more rows\n\nts_lyrics_df2 <- ts_lyrics_df2 %>%\ninner_join(get_sentiments(\"bing\"))%>%                                 \n  slice(1:25)\n\nJoining, by = \"word\"\n\nts_lyrics_df2\n\n# A tibble: 25 × 3\n   word          n sentiment\n   <chr>     <int> <chr>    \n 1 love        248 positive \n 2 bad          80 negative \n 3 shake        73 negative \n 4 break        59 negative \n 5 mad          48 negative \n 6 beautiful    46 positive \n 7 smile        45 positive \n 8 hate         44 negative \n 9 fall         43 negative \n10 whoa         36 positive \n# … with 15 more rows\n\n\n\nts_lyrics_df2 %>% \n  slice(1:25) %>% \n  ggplot(aes(fill = sentiment, y = fct_reorder(word,\n                         n), x= n))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Frequency of Word\", y= \"Sentiment Word\", title=\"Sentiment Word Frequency\", subtitle = \"Categorized by negative and positive sentiments\")+ \n  scale_fill_discrete(name = \"Sentiment\")\n\n\n\n\n\nlibrary(wordcloud)\nts_lyrics_df2 %>% \n  slice(1:25) %>% \n  with(wordcloud(word, n))\n\n\n\n\n\n# Using the `ts_lyrics` dataset,\n\n# Tokenize each lyrical line by words.\n# Remove the \"stopwords\".\n# Calculate the total number for each word in the lyrics **for each Album**.\n# Using the \"afinn\" sentiment lexicon, add a column to the summarized data frame adding the \"afinn\" sentiment lexicon.\n# Calculate the average sentiment score **for each Album**.\n# Auto print the wrangled tibble data frame.\n\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(textdata)\n\n\nts_lyrics2 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) \n\nts_lyrics_df3 = tibble(Album = ts_lyrics2$Album, line= ts_lyrics2$line) \nts_lyrics_df3 <- ts_lyrics_df3 %>% \n  group_by(Album)\nts_lyrics_df3\n\n# A tibble: 7,168 × 2\n# Groups:   Album [8]\n   Album        line                                                       \n   <chr>        <chr>                                                      \n 1 Taylor Swift \"He said the way my blue eyes shinx\"                       \n 2 Taylor Swift \"Put those Georgia stars to shame that night\"              \n 3 Taylor Swift \"I said: \\\"That's a lie.\\\"\"                                \n 4 Taylor Swift \"Just a boy in a Chevy truck\"                              \n 5 Taylor Swift \"That had a tendency of gettin' stuck\"                     \n 6 Taylor Swift \"On back roads at night\"                                   \n 7 Taylor Swift \"And I was right there beside him all summer long\"         \n 8 Taylor Swift \"And then the time we woke up to find that summer had gone\"\n 9 Taylor Swift \"But when you think \\\"Tim McGraw\\\"\"                        \n10 Taylor Swift \"I hope you think my favorite song\"                        \n# … with 7,158 more rows\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \n unnest_tokens(output = word, \n                input = line, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nts_lyrics_df3\n\n# A tibble: 4,968 × 3\n# Groups:   Album [8]\n   Album word         n\n   <chr> <chr>    <int>\n 1 1989  love        82\n 2 1989  shake       70\n 3 Red   time        66\n 4 Lover ooh         61\n 5 Red   uh          50\n 6 Red   red         46\n 7 Lover love        44\n 8 Lover wanna       42\n 9 1989  baby        41\n10 Lover daylight    40\n# … with 4,958 more rows\n\n\n\n#  Join the wrangled data frame from Part 1A (album sales in millions) with the wrangled data frame from #6 above (average sentiment score for each album).\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \ninner_join(get_sentiments(\"afinn\")) \n\nJoining, by = \"word\"\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \n  group_by(Album)%>%\n  summarise(average = mean(value))\nts_lyrics_df3\n\n# A tibble: 8 × 2\n  Album         average\n  <chr>           <dbl>\n1 1989         -0.822  \n2 Fearless      0.0192 \n3 folklore     -0.613  \n4 Lover        -0.429  \n5 Red          -0.00870\n6 reputation   -0.495  \n7 Speak Now    -0.365  \n8 Taylor Swift  0.137  \n\n\n\nsalesdf <- salesdf %>%\n  rename(Album = title)\n\n\nsalesdf\n\n# A tibble: 36 × 8\n   artist       Album        country  sales released   re_release  label formats\n   <chr>        <chr>        <fct>    <dbl> <date>     <chr>       <chr> <chr>  \n 1 Taylor Swift Taylor Swift US       5.72  2006-10-24 March 18, … Big … CD, CD…\n 2 Taylor Swift Fearless     World   12     2008-11-11 October 27… Big … CD, CD…\n 3 Taylor Swift Fearless     US       7.18  2008-11-11 October 27… Big … CD, CD…\n 4 Taylor Swift Fearless     UK       0.609 2008-11-11 October 27… Big … CD, CD…\n 5 Taylor Swift Speak Now    World    5     2010-10-25 <NA>        Big … CD, CD…\n 6 Taylor Swift Speak Now    US       4.69  2010-10-25 <NA>        Big … CD, CD…\n 7 Taylor Swift Speak Now    UK       0.169 2010-10-25 <NA>        Big … CD, CD…\n 8 Taylor Swift Red          World    6     2012-10-22 <NA>        Big … CD, CD…\n 9 Taylor Swift Red          US       4.46  2012-10-22 <NA>        Big … CD, CD…\n10 Taylor Swift Red          UK       0.693 2012-10-22 <NA>        Big … CD, CD…\n# … with 26 more rows\n\nts_lyrics_df3\n\n# A tibble: 8 × 2\n  Album         average\n  <chr>           <dbl>\n1 1989         -0.822  \n2 Fearless      0.0192 \n3 folklore     -0.613  \n4 Lover        -0.429  \n5 Red          -0.00870\n6 reputation   -0.495  \n7 Speak Now    -0.365  \n8 Taylor Swift  0.137  \n\ndataf <- inner_join(ts_lyrics_df3, salesdf, 'Album')\ndataf\n\n# A tibble: 16 × 9\n   Album         average artist  country  sales released   re_re…¹ label formats\n   <chr>           <dbl> <chr>   <fct>    <dbl> <date>     <chr>   <chr> <chr>  \n 1 1989         -0.822   Taylor… World   10.1   2014-10-27 <NA>    Big … CD, CD…\n 2 1989         -0.822   Taylor… US       6.22  2014-10-27 <NA>    Big … CD, CD…\n 3 1989         -0.822   Taylor… UK       1.25  2014-10-27 <NA>    Big … CD, CD…\n 4 Fearless      0.0192  Taylor… World   12     2008-11-11 Octobe… Big … CD, CD…\n 5 Fearless      0.0192  Taylor… US       7.18  2008-11-11 Octobe… Big … CD, CD…\n 6 Fearless      0.0192  Taylor… UK       0.609 2008-11-11 Octobe… Big … CD, CD…\n 7 Lover        -0.429   Taylor… World    3.2   2019-08-23 <NA>    Repu… CD, LP…\n 8 Lover        -0.429   Taylor… US       1.08  2019-08-23 <NA>    Repu… CD, LP…\n 9 Lover        -0.429   Taylor… UK       0.222 2019-08-23 <NA>    Repu… CD, LP…\n10 Red          -0.00870 Taylor… World    6     2012-10-22 <NA>    Big … CD, CD…\n11 Red          -0.00870 Taylor… US       4.46  2012-10-22 <NA>    Big … CD, CD…\n12 Red          -0.00870 Taylor… UK       0.693 2012-10-22 <NA>    Big … CD, CD…\n13 Speak Now    -0.365   Taylor… World    5     2010-10-25 <NA>    Big … CD, CD…\n14 Speak Now    -0.365   Taylor… US       4.69  2010-10-25 <NA>    Big … CD, CD…\n15 Speak Now    -0.365   Taylor… UK       0.169 2010-10-25 <NA>    Big … CD, CD…\n16 Taylor Swift  0.137   Taylor… US       5.72  2006-10-24 March … Big … CD, CD…\n# … with abbreviated variable name ¹​re_release\n\n\n\n\nFinal Plot\n\n# Using `ggplot2`, create a scatter plot of the average sentiment score for each album (y-axis) and the album release data along the x-axis. Make the size of each point the album sales in millions.\n# Add a horizontal line at y-intercept=0.\n# Write 2-3 sentences interpreting the plot answering the question \"How has the sentiment of Taylor Swift's albums have changed over time?\". Add a title, subtitle, and useful axis labels.\n\ndataf %>%\nggplot(aes(x=released, y=average, color=Album, size = sales)) +\n  geom_point() + \n  geom_hline(yintercept=0, linetype=\"dashed\", color = \"red\")+\n  labs(x=\"Year of Release\", y= \"Average Sentiment Score\", title=\"Average sentiment Score by Year of Release\", subtitle = \"Averages Grouped by Album\", color = \"Album\", size = \"Sales in Millions\")\n\n\n\n\n\n\nSummary\nThe sentiment of Taylor’s albums have gotten more negative over time, as we can see the very first album has the highest positive average score. Positivity rebounded a bit after being at its lowest with the album 1989. Sales seemed to not be affected by change in sentiment and is likely correlated with some other variable. However, most albums have more negative average sentiment than positive, as most albums fall below the 0 line, where positivity and negativity are equal.\nThis may be a trend overall, across the music industry. According to a study of sentiment of popular songs written from 1951 to 2016, there has been an increase in negative sentiment over time in lyrics (Napier and Shamir 2018). Further diving into what this has to do with album sales could be interesting.\n\n\nList of Functions\nglimpse(), lubridate(), stringr(), forcats(), ggplot(), textdata(), separate_rows(), inner_join(), slice(), anti_join(), wordcloud(), mutate()\n\n\n\n\n\nReferences\n\nFekadu, Mesfin. 2019. “Beyoncé, Taylor Swift, Elton John, J. Lo up for Globes.” NBC: Golden Globes, December 9, 2019. https://www.nbcbayarea.com/news/national-international/beyonce-taylor-swift-elton-john-j-lo-up-for-globes/2191945/.\n\n\nLawrence Technological University. 2019. “Popular Music Lyrics Become Angrier and Sadder over Time.” ScienceDaily 24 (January). www.sciencedaily.com/releases/2019/01/190124124737.htm.\n\n\nNapier, Kathleen, and Lior Shamir. 2018. “Quantitative Sentiment Analysis of Lyrics in Popular Music.” Journal of Popular Music Studies 30 (4): 161–76. https://doi.org/10.1525/jpms.2018.300411."
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-1a",
    "href": "DataAnalysisProj1_final.html#part-1a",
    "title": "DataAnalysisProj1",
    "section": "Part 1A",
    "text": "Part 1A\nIn this section, we will do some data wrangling.\n\nUse lubridate to create a column called released that is a Date class. However, to be able to do this, you first need to use stringr to search for pattern that matches things like this “(US)[51]” in a string like this “September 1, 2006 (US)[51]” and removes them. (Note: to get full credit, you must create the regular expression).\nUse forcats to create a factor called country (Note: you may need to collapse some factor levels).\n\n\nsales <- readRDS(here(\"data\",\"sales.RDS\"))\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(stringr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nsales$released <- str_remove_all(string=sales$released, pattern = \"(US)|(UK)|[\\\\[\\\\]\\\\(\\\\)]|(39)|(51)\")\n\nsales <- sales %>% \n  mutate(released=mdy(released)) %>% \n  mutate(country = as.factor(country)) %>%\n  mutate(country = fct_collapse(country,\n  World = c(\"WW\", \"World\"),\n  FR = c(\"FR\", \"FRA\")\n))\n\n\nTransform the sales into a unit that is album sales in millions of dollars.\n\n\nsales$sales <-  as.numeric(sales$sales)/1000000\n\n\nKeep only album sales from the UK, the US or the World.\nAuto print your final wrangled tibble data frame.\n\n\nsalesdf <- sales %>% \n   filter(country == \"UK\"|country == \"US\"| country == \"World\")\nsalesdf\n\n# A tibble: 36 × 8\n   artist       title        country  sales released   re_release  label formats\n   <chr>        <chr>        <fct>    <dbl> <date>     <chr>       <chr> <chr>  \n 1 Taylor Swift Taylor Swift US       5.72  2006-10-24 March 18, … Big … CD, CD…\n 2 Taylor Swift Fearless     World   12     2008-11-11 October 27… Big … CD, CD…\n 3 Taylor Swift Fearless     US       7.18  2008-11-11 October 27… Big … CD, CD…\n 4 Taylor Swift Fearless     UK       0.609 2008-11-11 October 27… Big … CD, CD…\n 5 Taylor Swift Speak Now    World    5     2010-10-25 <NA>        Big … CD, CD…\n 6 Taylor Swift Speak Now    US       4.69  2010-10-25 <NA>        Big … CD, CD…\n 7 Taylor Swift Speak Now    UK       0.169 2010-10-25 <NA>        Big … CD, CD…\n 8 Taylor Swift Red          World    6     2012-10-22 <NA>        Big … CD, CD…\n 9 Taylor Swift Red          US       4.46  2012-10-22 <NA>        Big … CD, CD…\n10 Taylor Swift Red          UK       0.693 2012-10-22 <NA>        Big … CD, CD…\n# … with 26 more rows"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-1b",
    "href": "DataAnalysisProj1_final.html#part-1b",
    "title": "DataAnalysisProj1",
    "section": "Part 1B",
    "text": "Part 1B\nIn this section, we will do some more data wrangling followed by summarization using wrangled data from Part 1A.\n\nKeep only album sales from the US.\n\n\nsales1 <- sales %>% \n   filter(country == \"US\")\n\n\nCreate a new column called years_since_release corresponding to the number of years since the release of each album from Beyoncé and Taylor Swift. This should be a whole number and you should round down to “14” if you get a non-whole number like “14.12” years. (Hint: you may find the interval() function from lubridate helpful here, but this is not the only way to do this.)\n\n\nsales1 <- sales %>% \n    mutate(years_since_release=(year(Sys.Date())-year(released)))\n\n\nCalculate the most recent, oldest, and the median years since albums were released for both Beyoncé and Taylor Swift.\n\n\nsales1 %>% \n  filter(artist==\"Taylor Swift\")%>%\n  summarize(median = median(years_since_release),\n            recent = min(years_since_release), \n            oldest = max(years_since_release))\n\n# A tibble: 1 × 3\n  median recent oldest\n   <dbl>  <dbl>  <dbl>\n1      8      2     16\n\nsales1 %>% \n  filter(artist==\"Beyoncé\")%>%\n  summarize(median = median(years_since_release),\n            recent = min(years_since_release), \n            oldest = max(years_since_release))\n\n# A tibble: 1 × 3\n  median recent oldest\n   <dbl>  <dbl>  <dbl>\n1   12.5      6     19"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-1c",
    "href": "DataAnalysisProj1_final.html#part-1c",
    "title": "DataAnalysisProj1",
    "section": "Part 1C",
    "text": "Part 1C\nUsing the wrangled data from Part 1A:\n\nCalculate the total album sales for each artist and for each country (only sales from the UK, US, and World).\n\n\nsales2 <- sales %>% \n  filter(country == \"UK\"|country == \"US\"| country == \"World\")%>%\n  group_by(artist, country) %>%\n  summarize(total = sum(sales))\n\n`summarise()` has grouped output by 'artist'. You can override using the\n`.groups` argument.\n\nsales2\n\n# A tibble: 6 × 3\n# Groups:   artist [2]\n  artist       country total\n  <chr>        <fct>   <dbl>\n1 Beyoncé      UK       5.24\n2 Beyoncé      US      17.7 \n3 Beyoncé      World   34.5 \n4 Taylor Swift UK       3.32\n5 Taylor Swift US      31.7 \n6 Taylor Swift World   40.8 \n\n\n\nUsing the total album sales, create a percent stacked barchart using ggplot2 of the percentage of sales of studio albums (in millions) along the y-axis for the two artists along the x-axis colored by the country.\n\n\nggplot(sales2,aes(fill=artist, y=total, x=country)) + \n    geom_bar(position=\"fill\", stat=\"identity\") +\n    ggtitle(label = \"ALbum Sales\",\n              subtitle = \"As a Percentage by Artist Seperated by Country\") +\n    xlab(\"Country\") + \n  ylab(\"Precentage of Sales\")+ \n  scale_fill_discrete(name = \"Artist\")"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-1d",
    "href": "DataAnalysisProj1_final.html#part-1d",
    "title": "DataAnalysisProj1",
    "section": "Part 1D",
    "text": "Part 1D\nUsing the wrangled data from Part 1A, use ggplot2 to create a bar plot for the sales of studio albums (in millions) along the x-axis for each of the album titles along the y-axis.\nNote:\n\nYou only need to consider the global World sales (you can ignore US and UK sales for this part).\n\n\nsales3 <- sales %>% \n   filter(country == \"World\")\n\n\nThe title of the album must be clearly readable along the y-axis.\nEach bar should be colored by which artist made that album.\nThe bars should be ordered from albums with the most sales (top) to the least sales (bottom) (Note: you must use functions from forcats for this step).\n\n\n#ggplot(sales, aes(fill=artist, y=title, x=sales)) + \n    #geom_bar(position=\"dodge\", stat=\"identity\")\n\nsales3 %>% \n  ggplot(aes(fill = artist, y = fct_reorder(title,\n                         sales), x= sales))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Sales in Millions\", y= \"Album Title\", title=\"Sales in Millions\", subtitle = \"By Album Title and Artist\")+ \n  scale_fill_discrete(name = \"Artist\")+ \n  theme(axis.text.y = element_text(angle = 45))"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-1e",
    "href": "DataAnalysisProj1_final.html#part-1e",
    "title": "DataAnalysisProj1",
    "section": "Part 1E",
    "text": "Part 1E\nUsing the wrangled data from Part 1A, use ggplot2 to create a scatter plot of sales of studio albums (in millions) along the y-axis by the released date for each album along the x-axis.\nNote:\n\nThe points should be colored by the artist.\nThere should be three scatter plots (one for UK, US and world sales) faceted by rows.\n\n\n# Add your solution here\nsales %>%\n  filter(country == \"UK\"|country == \"US\"| country == \"World\")%>%\nggplot(aes(x=released, y=sales, color=artist)) +\n  geom_point() + \n  facet_grid(country ~ .)+\n  labs(x=\"Year of Release\", y= \"Sales in Millions\", title=\"Sales in Millions by Year of Release\", subtitle = \"Faceted by Country\", color = \"Artist\")"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-2a",
    "href": "DataAnalysisProj1_final.html#part-2a",
    "title": "DataAnalysisProj1",
    "section": "Part 2A",
    "text": "Part 2A\nUsing ts_lyrics, create a new column called line with one line containing the character string for each line of Taylor Swift’s songs.\n\nb_lyrics <- readRDS(here(\"data\",\"b_lyrics.RDS\"))\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(tidytext) \nts_lyrics\n\n# A tibble: 132 × 4\n   Artist       Album        Title                      Lyrics                  \n   <chr>        <chr>        <chr>                      <chr>                   \n 1 Taylor Swift Taylor Swift Tim McGraw                 \"He said the way my blu…\n 2 Taylor Swift Taylor Swift Picture to Burn            \"State the obvious, I d…\n 3 Taylor Swift Taylor Swift Teardrops on my Guitar     \"Drew looks at me,\\nI f…\n 4 Taylor Swift Taylor Swift A Place in This World      \"I don't know what I wa…\n 5 Taylor Swift Taylor Swift Cold As You                \"You have a way of comi…\n 6 Taylor Swift Taylor Swift The Outside                \"I didn't know what I w…\n 7 Taylor Swift Taylor Swift Tied Together With A Smile \"Seems the only one who…\n 8 Taylor Swift Taylor Swift Stay Beautiful             \"Cory's eyes are like a…\n 9 Taylor Swift Taylor Swift Should’ve Said No          \"It's strange to think …\n10 Taylor Swift Taylor Swift Mary’s Song                \"She said\\n\\\"I was seve…\n# … with 122 more rows\n\nb_lyrics\n\n# A tibble: 22,616 × 6\n   line                                  song_id song_…¹ artis…² artis…³ song_…⁴\n   <chr>                                   <dbl> <chr>     <dbl> <chr>     <dbl>\n 1 If I ain't got nothing, I got you       50396 1+1         498 Beyoncé       1\n 2 If I ain't got something, I don't gi…   50396 1+1         498 Beyoncé       2\n 3 'Cause I got it with you                50396 1+1         498 Beyoncé       3\n 4 I don't know much about algebra, but…   50396 1+1         498 Beyoncé       4\n 5 And it's me and you                     50396 1+1         498 Beyoncé       5\n 6 That's all we'll have when the world…   50396 1+1         498 Beyoncé       6\n 7 'Cause baby, we ain't got nothing wi…   50396 1+1         498 Beyoncé       7\n 8 Darling, you got enough for the both…   50396 1+1         498 Beyoncé       8\n 9 So come on, baby, make love to me       50396 1+1         498 Beyoncé       9\n10 When my days look low                   50396 1+1         498 Beyoncé      10\n# … with 22,606 more rows, and abbreviated variable names ¹​song_name,\n#   ²​artist_id, ³​artist_name, ⁴​song_line\n\n\n\nHow many lines in Taylor Swift’s lyrics contain the word “hello”?\n\nFor full credit, show all the rows in ts_lyrics that have “hello” in the line column and report how many rows there are in total."
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-2a-1",
    "href": "DataAnalysisProj1_final.html#part-2a-1",
    "title": "DataAnalysisProj1",
    "section": "Part 2A",
    "text": "Part 2A\nUsing ts_lyrics, create a new column called line with one line containing the character string for each line of Taylor Swift’s songs.\n\nHow many lines in Taylor Swift’s lyrics contain the word “hello”?\n\nFor full credit, show all the rows in ts_lyrics that have “hello” in the line column and report how many rows there are in total.\n\nHow many lines in Taylor Swift’s lyrics contain the word “goodbye”? For full credit, show all the rows in ts_lyrics that have “goodbye” in the line column and report how many rows there are in total.\n\n\nb_lyrics <- readRDS(here(\"data\",\"b_lyrics.RDS\"))\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(tidytext) \n\n\nts_lyrics_df = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number()) %>%\n    mutate(hello_ind = ifelse(grepl(pattern = \"hello\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(hello_ind == 1) \n    \nts_lyrics_df\n\n# A tibble: 6 × 6\n  Artist       Album    Title                  line              song_…¹ hello…²\n  <chr>        <chr>    <chr>                  <chr>               <int>   <dbl>\n1 Taylor Swift Fearless Love Story             \"And say, \\\"Hell…     932       1\n2 Taylor Swift Red      I Almost Do            \"That I can't sa…    2711       1\n3 Taylor Swift Red      Everything Has Changed \"'Cause all I kn…    3040       1\n4 Taylor Swift Red      Everything Has Changed \"'Cause all I kn…    3059       1\n5 Taylor Swift Red      Everything Has Changed \"All I know is w…    3074       1\n6 Taylor Swift Red      Everything Has Changed \"All I know is w…    3082       1\n# … with abbreviated variable names ¹​song_line, ²​hello_ind\n\nnrow(ts_lyrics_df)\n\n[1] 6\n\n\n\nts_lyrics_df1 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number()) %>%\n    mutate(goodbye_ind = ifelse(grepl(pattern = \"goodbye\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(goodbye_ind == 1) \n    \nts_lyrics_df1\n\n# A tibble: 12 × 6\n   Artist       Album        Title                      line     song_…¹ goodb…²\n   <chr>        <chr>        <chr>                      <chr>      <int>   <dbl>\n 1 Taylor Swift Taylor Swift Tied Together With A Smile \"Goodby…     273       1\n 2 Taylor Swift Speak Now    Mine                       \"Braced…    1457       1\n 3 Taylor Swift Speak Now    Back to December           \"You ga…    1547       1\n 4 Taylor Swift Speak Now    Long Live                  \"And fo…    2154       1\n 5 Taylor Swift Red          I Almost Do                \"And ri…    2712       1\n 6 Taylor Swift Red          Come Back Be Here          \"Stumbl…    3243       1\n 7 Taylor Swift 1989         All You Had to Do Was Stay \"But pe…    3639       1\n 8 Taylor Swift reputation   Getaway Car                \"Said g…    4908       1\n 9 Taylor Swift reputation   Getaway Car                \"Said g…    4916       1\n10 Taylor Swift Lover        Death By A Thousand Cuts   \"Saying…    5817       1\n11 Taylor Swift Lover        Death By A Thousand Cuts   \"'Cause…    5837       1\n12 Taylor Swift Lover        Daylight                   \"I'll t…    6222       1\n# … with abbreviated variable names ¹​song_line, ²​goodbye_ind\n\nnrow(ts_lyrics_df1)\n\n[1] 12\n\n\nTHIS IS CODE CHUNK IS JUST FOR MY OWN LEARNING PLEASE DO NOT GRADE\nts_lyrics_df = tibble(text = ts_lyrics$Lyrics)\nts_lyrics_df <- ts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) ts_lyrics_df\nts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) %>% mutate(hello_ind = ifelse(grepl(pattern = “hello”, x = line, ignore.case = TRUE),1,0)) %>% filter(hello_ind == 1)\nts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) %>% mutate(hello_ind = ifelse(grepl(pattern = “hello”, x = line, ignore.case = TRUE),1,0)) %>% filter(hello_ind == 1) %>% summarise(sum_hello = sum(hello_ind))\nts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) %>% mutate(goodbye_ind = ifelse(grepl(pattern = “goodbye”, x = line, ignore.case = TRUE),1,0)) %>% filter(goodbye_ind == 1)\nts_lyrics_df %>% unnest_tokens(line, text, token = stringr::str_split, pattern = “”) %>% mutate(song_line = row_number()) %>% mutate(goodbye_ind = ifelse(grepl(pattern = “goodbye”, x = line, ignore.case = TRUE),1,0)) %>% filter(goodbye_ind == 1) %>% summarise(sum_goodbye = sum(goodbye_ind))"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-2b",
    "href": "DataAnalysisProj1_final.html#part-2b",
    "title": "DataAnalysisProj1",
    "section": "Part 2B",
    "text": "Part 2B\nRepeat the same analysis for b_lyrics as described in Part 2A.\n\nb_lyrics_df = b_lyrics %>%\n    mutate(hello_ind = ifelse(grepl(pattern = \"hello\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(hello_ind == 1) \n    \nb_lyrics_df\n\n# A tibble: 91 × 7\n   line                          song_id song_…¹ artis…² artis…³ song_…⁴ hello…⁵\n   <chr>                           <dbl> <chr>     <dbl> <chr>     <dbl>   <dbl>\n 1 Hello world, well I just bou… 2220711 \"Dream…     498 Beyoncé       5       1\n 2 Hello Stevie, How you feeling 1981227 \"Finge…     498 Beyoncé       6       1\n 3 Fellow great Americans, hello 2715227 \"FREED…     498 Beyoncé      52       1\n 4 You had me at hello (Hello)     80249 \"Hello\"     498 Beyoncé      15       1\n 5 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      16       1\n 6 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      17       1\n 7 You had me at hello (Hello)     80249 \"Hello\"     498 Beyoncé      18       1\n 8 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      19       1\n 9 Hello (Hello)                   80249 \"Hello\"     498 Beyoncé      20       1\n10 'Cause you had me at hello (…   80249 \"Hello\"     498 Beyoncé      24       1\n# … with 81 more rows, and abbreviated variable names ¹​song_name, ²​artist_id,\n#   ³​artist_name, ⁴​song_line, ⁵​hello_ind\n\nnrow(b_lyrics_df)\n\n[1] 91\n\n\n\nb_lyrics_df1 = b_lyrics %>%\n    mutate(goodbye_ind = ifelse(grepl(pattern = \"goodbye\", x = line, ignore.case = TRUE),1,0)) %>%\n    filter(goodbye_ind == 1) \n    \nb_lyrics_df1\n\n# A tibble: 12 × 7\n   line                          song_id song_…¹ artis…² artis…³ song_…⁴ goodb…⁵\n   <chr>                           <dbl> <chr>     <dbl> <chr>     <dbl>   <dbl>\n 1 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      12       1\n 2 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      21       1\n 3 We only said goodbye with wo…  139043 Back t…     498 Beyoncé      24       1\n 4 Thank God, I found the good …   51492 Best T…     498 Beyoncé      38       1\n 5 Thank God, I found the good … 1946060 Best T…     498 Beyoncé      42       1\n 6 Thank God, I found the good … 4241137 Best T…     498 Beyoncé      38       1\n 7 It's so hard to say goodbye    435491 Gift f…     498 Beyoncé      23       1\n 8 I never want to say goodbye    435491 Gift f…     498 Beyoncé      24       1\n 9 I never, ever want to say go…  435491 Gift f…     498 Beyoncé      25       1\n10 We've got to say goodbye      1844620 Hard T…     498 Beyoncé      29       1\n11 Don't have to say goodbye     1224115 Slow L…     498 Beyoncé      42       1\n12 Somewhere between hi and goo…  141848 Yes         498 Beyoncé      27       1\n# … with abbreviated variable names ¹​song_name, ²​artist_id, ³​artist_name,\n#   ⁴​song_line, ⁵​goodbye_ind\n\nnrow(b_lyrics_df1)\n\n[1] 12"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-2c",
    "href": "DataAnalysisProj1_final.html#part-2c",
    "title": "DataAnalysisProj1",
    "section": "Part 2C",
    "text": "Part 2C\nUsing the b_lyrics dataset,\n\nTokenize each lyrical line by words.\nRemove the “stopwords”.\nCalculate the total number for each word in the lyrics.\nUsing the “bing” sentiment lexicon, add a column to the summarized data frame adding the “bing” sentiment lexicon.\nSort the rows from most frequent to least frequent words.\nOnly keep the top 25 most frequent words.\nAuto print the wrangled tibble data frame.\nUse ggplot2 to create a bar plot with the top words on the y-axis and the frequency of each word on the x-axis. Color each bar by the sentiment of each word from the “bing” sentiment lexicon. Bars should be ordered from most frequent on the top to least frequent on the bottom of the plot.\nCreate a word cloud of the top 25 most frequent words.\n\n\nb_lyrics_df2 = tibble(text = b_lyrics$line) \n\nb_lyrics_df2n <- b_lyrics_df2 %>% \n unnest_tokens(output = word, \n                input = text, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nb_lyrics_df2n\n\n# A tibble: 5,937 × 2\n   word      n\n   <chr> <int>\n 1 love   1362\n 2 baby   1024\n 3 girl    592\n 4 wanna   564\n 5 hey     499\n 6 boy     494\n 7 yeah    491\n 8 feel    488\n 9 time    452\n10 uh      408\n# … with 5,927 more rows\n\nb_lyrics_df2n <- b_lyrics_df2n %>%\ninner_join(get_sentiments(\"bing\"))%>%                                 \n  slice(1:25)\n\nJoining, by = \"word\"\n\nb_lyrics_df2n\n\n# A tibble: 25 × 3\n   word          n sentiment\n   <chr>     <int> <chr>    \n 1 love       1362 positive \n 2 crazy       308 negative \n 3 top         241 positive \n 4 bad         132 negative \n 5 beautiful   131 positive \n 6 whoa        121 positive \n 7 damn        106 negative \n 8 hurt         90 negative \n 9 hard         87 negative \n10 ready        85 positive \n# … with 15 more rows\n\n\n\nb_lyrics_df2n %>% \n  slice(1:25) %>% \n  ggplot(aes(fill = sentiment, y = fct_reorder(word,\n                         n), x= n))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Frequency of Word\", y= \"Sentiment Word\", title=\"Sentiment Word Frequency\")+ \n  scale_fill_discrete(name = \"Sentiment\")\n\n\n\n\n\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\nb_lyrics_df2n %>% \n  slice(1:25) %>% \n  with(wordcloud(word, n))"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-2d",
    "href": "DataAnalysisProj1_final.html#part-2d",
    "title": "DataAnalysisProj1",
    "section": "Part 2D",
    "text": "Part 2D\nRepeat the same analysis as above in Part 2C, but for ts_lyrics.\n\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nts_lyrics1 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) %>%\n    mutate(song_line = row_number())\n\nts_lyrics_df2 = tibble(text = ts_lyrics1$line) \n\nts_lyrics_df2 <- ts_lyrics_df2 %>% \n unnest_tokens(output = word, \n                input = text, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nts_lyrics_df2\n\n# A tibble: 2,579 × 2\n   word      n\n   <chr> <int>\n 1 love    248\n 2 time    225\n 3 wanna   158\n 4 baby    153\n 5 ooh     127\n 6 yeah    105\n 7 stay    100\n 8 gonna    98\n 9 night    96\n10 bad      80\n# … with 2,569 more rows\n\nts_lyrics_df2 <- ts_lyrics_df2 %>%\ninner_join(get_sentiments(\"bing\"))%>%                                 \n  slice(1:25)\n\nJoining, by = \"word\"\n\nts_lyrics_df2\n\n# A tibble: 25 × 3\n   word          n sentiment\n   <chr>     <int> <chr>    \n 1 love        248 positive \n 2 bad          80 negative \n 3 shake        73 negative \n 4 break        59 negative \n 5 mad          48 negative \n 6 beautiful    46 positive \n 7 smile        45 positive \n 8 hate         44 negative \n 9 fall         43 negative \n10 whoa         36 positive \n# … with 15 more rows\n\n\n\nts_lyrics_df2 %>% \n  slice(1:25) %>% \n  ggplot(aes(fill = sentiment, y = fct_reorder(word,\n                         n), x= n))+\n  geom_bar(position=\"dodge\", stat=\"identity\")+\n  labs(x=\"Frequency of Word\", y= \"Sentiment Word\", title=\"Sentiment Word Frequency\", subtitle = \"Categorized by negative and positive sentiments\")+ \n  scale_fill_discrete(name = \"Sentiment\")\n\n\n\n\n\nlibrary(wordcloud)\nts_lyrics_df2 %>% \n  slice(1:25) %>% \n  with(wordcloud(word, n))"
  },
  {
    "objectID": "DataAnalysisProj1_final.html#part-2e",
    "href": "DataAnalysisProj1_final.html#part-2e",
    "title": "DataAnalysisProj1",
    "section": "Part 2E",
    "text": "Part 2E\nUsing the ts_lyrics dataset,\n\nTokenize each lyrical line by words.\nRemove the “stopwords”.\nCalculate the total number for each word in the lyrics for each Album.\nUsing the “afinn” sentiment lexicon, add a column to the summarized data frame adding the “afinn” sentiment lexicon.\nCalculate the average sentiment score for each Album.\nAuto print the wrangled tibble data frame.\n\n\nts_lyrics <- readRDS(here(\"data\",\"ts_lyrics.RDS\"))\nlibrary(textdata)\n\n\nts_lyrics2 = separate_rows(ts_lyrics, Lyrics, sep = '\\n') %>%\nrename(line = Lyrics) \n\nts_lyrics_df3 = tibble(Album = ts_lyrics2$Album, line= ts_lyrics2$line) \nts_lyrics_df3 <- ts_lyrics_df3 %>% \n  group_by(Album)\nts_lyrics_df3\n\n# A tibble: 7,168 × 2\n# Groups:   Album [8]\n   Album        line                                                       \n   <chr>        <chr>                                                      \n 1 Taylor Swift \"He said the way my blue eyes shinx\"                       \n 2 Taylor Swift \"Put those Georgia stars to shame that night\"              \n 3 Taylor Swift \"I said: \\\"That's a lie.\\\"\"                                \n 4 Taylor Swift \"Just a boy in a Chevy truck\"                              \n 5 Taylor Swift \"That had a tendency of gettin' stuck\"                     \n 6 Taylor Swift \"On back roads at night\"                                   \n 7 Taylor Swift \"And I was right there beside him all summer long\"         \n 8 Taylor Swift \"And then the time we woke up to find that summer had gone\"\n 9 Taylor Swift \"But when you think \\\"Tim McGraw\\\"\"                        \n10 Taylor Swift \"I hope you think my favorite song\"                        \n# … with 7,158 more rows\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \n unnest_tokens(output = word, \n                input = line, \n                token=\"words\") %>% \n    anti_join(stop_words)%>%\n    count(word, sort = TRUE) \n\nJoining, by = \"word\"\n\nts_lyrics_df3\n\n# A tibble: 4,968 × 3\n# Groups:   Album [8]\n   Album word         n\n   <chr> <chr>    <int>\n 1 1989  love        82\n 2 1989  shake       70\n 3 Red   time        66\n 4 Lover ooh         61\n 5 Red   uh          50\n 6 Red   red         46\n 7 Lover love        44\n 8 Lover wanna       42\n 9 1989  baby        41\n10 Lover daylight    40\n# … with 4,958 more rows\n\n\n\nJoin the wrangled data frame from Part 1A (album sales in millions) with the wrangled data frame from #6 above (average sentiment score for each album).\n\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \ninner_join(get_sentiments(\"afinn\")) \n\nJoining, by = \"word\"\n\nts_lyrics_df3 <- ts_lyrics_df3 %>% \n  group_by(Album)%>%\n  summarise(average = mean(value))\nts_lyrics_df3\n\n# A tibble: 8 × 2\n  Album         average\n  <chr>           <dbl>\n1 1989         -0.822  \n2 Fearless      0.0192 \n3 folklore     -0.613  \n4 Lover        -0.429  \n5 Red          -0.00870\n6 reputation   -0.495  \n7 Speak Now    -0.365  \n8 Taylor Swift  0.137  \n\n\n\nsalesdf <- salesdf %>%\n  rename(Album = title)\n\n\nsalesdf\n\n# A tibble: 36 × 8\n   artist       Album        country  sales released   re_release  label formats\n   <chr>        <chr>        <fct>    <dbl> <date>     <chr>       <chr> <chr>  \n 1 Taylor Swift Taylor Swift US       5.72  2006-10-24 March 18, … Big … CD, CD…\n 2 Taylor Swift Fearless     World   12     2008-11-11 October 27… Big … CD, CD…\n 3 Taylor Swift Fearless     US       7.18  2008-11-11 October 27… Big … CD, CD…\n 4 Taylor Swift Fearless     UK       0.609 2008-11-11 October 27… Big … CD, CD…\n 5 Taylor Swift Speak Now    World    5     2010-10-25 <NA>        Big … CD, CD…\n 6 Taylor Swift Speak Now    US       4.69  2010-10-25 <NA>        Big … CD, CD…\n 7 Taylor Swift Speak Now    UK       0.169 2010-10-25 <NA>        Big … CD, CD…\n 8 Taylor Swift Red          World    6     2012-10-22 <NA>        Big … CD, CD…\n 9 Taylor Swift Red          US       4.46  2012-10-22 <NA>        Big … CD, CD…\n10 Taylor Swift Red          UK       0.693 2012-10-22 <NA>        Big … CD, CD…\n# … with 26 more rows\n\nts_lyrics_df3\n\n# A tibble: 8 × 2\n  Album         average\n  <chr>           <dbl>\n1 1989         -0.822  \n2 Fearless      0.0192 \n3 folklore     -0.613  \n4 Lover        -0.429  \n5 Red          -0.00870\n6 reputation   -0.495  \n7 Speak Now    -0.365  \n8 Taylor Swift  0.137  \n\ndataf <- inner_join(ts_lyrics_df3, salesdf, 'Album')\ndataf\n\n# A tibble: 16 × 9\n   Album         average artist  country  sales released   re_re…¹ label formats\n   <chr>           <dbl> <chr>   <fct>    <dbl> <date>     <chr>   <chr> <chr>  \n 1 1989         -0.822   Taylor… World   10.1   2014-10-27 <NA>    Big … CD, CD…\n 2 1989         -0.822   Taylor… US       6.22  2014-10-27 <NA>    Big … CD, CD…\n 3 1989         -0.822   Taylor… UK       1.25  2014-10-27 <NA>    Big … CD, CD…\n 4 Fearless      0.0192  Taylor… World   12     2008-11-11 Octobe… Big … CD, CD…\n 5 Fearless      0.0192  Taylor… US       7.18  2008-11-11 Octobe… Big … CD, CD…\n 6 Fearless      0.0192  Taylor… UK       0.609 2008-11-11 Octobe… Big … CD, CD…\n 7 Lover        -0.429   Taylor… World    3.2   2019-08-23 <NA>    Repu… CD, LP…\n 8 Lover        -0.429   Taylor… US       1.08  2019-08-23 <NA>    Repu… CD, LP…\n 9 Lover        -0.429   Taylor… UK       0.222 2019-08-23 <NA>    Repu… CD, LP…\n10 Red          -0.00870 Taylor… World    6     2012-10-22 <NA>    Big … CD, CD…\n11 Red          -0.00870 Taylor… US       4.46  2012-10-22 <NA>    Big … CD, CD…\n12 Red          -0.00870 Taylor… UK       0.693 2012-10-22 <NA>    Big … CD, CD…\n13 Speak Now    -0.365   Taylor… World    5     2010-10-25 <NA>    Big … CD, CD…\n14 Speak Now    -0.365   Taylor… US       4.69  2010-10-25 <NA>    Big … CD, CD…\n15 Speak Now    -0.365   Taylor… UK       0.169 2010-10-25 <NA>    Big … CD, CD…\n16 Taylor Swift  0.137   Taylor… US       5.72  2006-10-24 March … Big … CD, CD…\n# … with abbreviated variable name ¹​re_release\n\n\n\nUsing ggplot2, create a scatter plot of the average sentiment score for each album (y-axis) and the album release data along the x-axis. Make the size of each point the album sales in millions.\nAdd a horizontal line at y-intercept=0.\nWrite 2-3 sentences interpreting the plot answering the question “How has the sentiment of Taylor Swift’s albums have changed over time?”. Add a title, subtitle, and useful axis labels.\n\n\ndataf %>%\nggplot(aes(x=released, y=average, color=Album, size = sales)) +\n  geom_point() + \n  geom_hline(yintercept=0, linetype=\"dashed\", color = \"red\")+\n  labs(x=\"Year of Release\", y= \"Average Sentiment Score\", title=\"Average sentiment Score by Year of Release\", subtitle = \"Averages Grouped by Album\", color = \"Album\", size = \"Sales in Millions\")\n\n\n\n\nWrite 2-3 sentences interpreting the plot answering the question “How has the sentiment of Taylor Swift’s albums have changed over time?”.\n\nConclusion\nThe sentiment of Taylor’s albums have gotten more negative over time, as we can see the very first album has the highest positive average score. Positivity rebounded a bit after being at its lowest with the album 1989. Sales seemed to not be affected by change in sentiment and is likely correlated with some other variable. However, most albums have more negative average sentiment than positive, as most albums fall below the 0 line, where positivity and negativity are equal."
  }
]